---
title: "Evaluation des algorithmes de ranking pour classer des produits sur un site de e-commerce"
output: pdf_document
date: "2025-12-08"
author: "Flavie Bertrand et Marion Tremblay" 
header-includes:
  - \usepackage{amsmath}
  - \usepackage{amssymb}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(kableExtra)
library(dplyr)
library(ggplot2)

if (!requireNamespace("Ranking", quietly = TRUE)) {
  if (!requireNamespace("remotes", quietly = TRUE))
    install.packages("remotes")
  remotes::install_github("mariontremblay49/Algorithmique")
}

library(Ranking)
```

# 1. Description du problème et objectif

## 1.1. Problème général de ranking 

On considère :

- \( i \in \{1, 2, \ldots, n\} \) : l'élément i
- un score associé à chaque élément : \( s_i \in \mathbb{R} \)
- une variable binaire \( x_{i,p} \in \{0,1\} \) qui vaut 1 si l'élément \( i \) est placé à la position \( p \) (0 sinon)
- un poids \( w_p \) associé à la position \( p \)

L'objectif est de déterminer un classement des \( k \) premiers éléments maximisant le score total.

\[
\max_x \sum_{i=1}^n \sum_{p=1}^k w_p\, s_i\, x_{i,p}
\]

**Sous contraintes : **

- Un élément ne peut occuper au plus qu'une seule position :

\[
\sum_{p=1}^k x_{i,p} \le 1,\quad \forall i
\]

- Chaque position doit être occupée par exactement un élément :

\[
\sum_{i=1}^m x_{i,p} = 1,\quad \forall p
\]

- Contraintes de groupes :

On définit des groupes :

\[
G_g \subseteq \{1,\ldots,m\}, \quad g = 1, \ldots, G
\]

On impose que chaque groupe \( G_g \) apparaisse au plus \( \alpha_g \) fois dans les \( k \) premiers :

\[
\sum_{i \in G_g} \sum_{p=1}^k x_{i,p} \le \alpha_g,\quad \forall g
\]


## 1.2. Exemple concret 

### 1.2.1. Contexte 

On applique ce problème pour sélectionner les 5 produits les plus pertinents pour les afficher sur la page d'accueil d'un site de e-commerce. Chaque produit a un score $s_i$ correspondant à la moyenne des notes données par les utilisateurs. On souhaite maximiser ce score tout en respectant certaines contraintes :

- Diversité des catégories : pas plus de 2 produits de la même catégorie 

- Contrainte marketing : au moins un produit sponsorisé doit apparaître dans le top 5

Pour répondre à ce problème on utilise la base de données des retours produits du site Amazon datant de 2018. Nous avons sélectionné un échantillon de 250 produits de cette base de données. Nous avons généré une colonne en plus pour réaliser la contrainte marketing, en associant 15% des produits de la base de données à des produits sponsorisés.


| Asin          | Score      | Category       | Sponsored     |
|---------------|------------|----------------|---------------|
| B00004ZCJI    | 4,4        | Electronics    | False         |
| B00004ZCJJ    | 4,4        | Electronics    | False         |
| B00079ULA8    | 4,1        | Sports         | False         |
| B000CBSNRY    | 4,9        | Toys_Games     | False         |
| B0001YR54E    | 4,5        | Clothing       |  True         |


| Id   | Score      | Groupe                        |
|------|------------|-------------------------------|
| 1    | 4,4        | Electronics, not_sponsored    |
| 2    | 4,4        | Electronics, not_sponsored    |
| 3    | 4,1        | Sports, not_sponsored         |
| 4    | 4,9        | Toys_Games, not_sponsored     |
| 5    | 4,5        | Clothing, sponsored           |


### 1.2.2. Formulation mathématique 

La fonction objectif est :

\[
\max_x \sum_{i=1}^n \sum_{p=1}^5 w_p\, s_i\, x_{i,p}
\]

où :

- \(x_{i,p}\) est une variable binaire qui vaut 1 si l'élément \( i \) est placé à la position \( p \) (0 sinon)
- \(w_p\) est le poids associé à la position \(p\): il vaut 5 à la position puis est décrémenter de 1 à chaque position suivante. 

**Sous contraintes**

- Chaque position contient exactement un produit :

\[
\sum_{i=1}^{n} x_{i,p} = 1 \quad \forall p
\]

- Un produit ne peut être affiché qu'une seule fois :

\[
\sum_{p=1}^{5} x_{i,p} \le 1 \quad \forall i
\]

- Maximum 2 produits par catégorie :

\[
\sum_{i \in \text{cat } c} \sum_{p=1}^{5} x_{i,p} \le 2
\]


- Au moins 1 produit sponsorisé dans le top 5 :

\[
\sum_{i \in \text{sponsored}} \sum_{p=1}^{5} x_{i,p} \ge 1
\]

Cette dernière contrainte est équivalente à avoir maximum 4 produits non sponsorisé dans le top 5, soit :
$$
\sum_{i \in \text{not sponsored} } \sum_{p=1}^{5} x_{i,p} \le 4
$$




# 2. Approche heuristique 

L'approche **heuristique** constitue une première stratégie simple pour résoudre le problème de ranking pondéré avec contraintes de groupes.


### Principe algorithmique

1. Initialiser les compteurs de chaque groupe à 0 et liste des éléments sélectionnés vide.

2. Pour chaque position (p = 1,\dots,k) :

   * Considérer les éléments non encore sélectionnés respectant les contraintes de groupes.
   * Choisir l'élément avec le gain immédiat maximal $w_p \cdot s_i$.
   * Mettre à jour les compteurs de groupes et le score total.

3. Arrêt si aucune sélection possible pour une position ou si toutes les positions sont remplies.

Cette méthode est très rapide et facile à implémenter, mais elle ne garantit pas d'optimalité globale, car elle ne considère pas les effets futurs de chaque choix.

### Exemple illustratif

On applique l'algorithme sur le jeu de données décrit en introduction :

```{r, message=FALSE, echo=FALSE}
# Paramètres
k <- 5
df <- read.csv("amazon_products_250.csv", stringsAsFactors = FALSE)
df$sponsored <- ifelse(df$sponsored == "True", "Sponsored", "Not_sponsored")
poids_positions <- seq(k, 1, by = -1)
liste_cat <- setNames(as.list(rep(2, length(unique(df$category)))), unique(df$category))
max_par_groupe <- c(liste_cat, list(Not_sponsored = 4))

# Échantillon
n <- 50
echantillon <- df[sample(nrow(df), min(n, nrow(df))), ]

# Construction du dataset
data_mat <- data.frame(
  id = 1:nrow(echantillon),
  score = echantillon$score,
  groupes = paste(echantillon$category, echantillon$sponsored, sep = ",")
)

# Vérifier que le dataset n'est pas vide
if(nrow(data_mat) > 0){
  res_naif <- ranking_naif_max(data_mat, k = k, max_par_groupe, poids_positions = poids_positions)
  res_naif$selected_items
  res_naif$best_score
} else {
  message("data_mat est vide, impossible d'appliquer ranking_naif_max")
}

res_naif <- ranking_naif_max(data_mat, k, max_par_groupe, poids_positions = poids_positions)
res_naif$selected_items
res_naif$best_score
```


* L'algorithme privilégie les éléments les mieux notés pour les premières positions.
* Les contraintes de groupe peuvent limiter le choix, ce qui peut conduire à des choix sous-optimaux pour les positions suivantes.
* Cette approche est rapide et simple.







# 3. Solution 1 : programmation dynamique 

## L'algorithme

Pour résoudre le problème de ranking sous contraintes de groupe et de poids positionnels, on utilise une programmation dynamique :

Chaque état est défini par :

* le nombre de positions déjà remplies,
* le nombre d'éléments choisis par groupe (compteurs de groupes).
* À chaque étape (position p), on essaie tous les éléments possibles qui respectent les contraintes de groupes et qui n'ont pas déjà été choisis.

À la fin, on récupère l'état final avec le score total maximal et la sélection correspondante.

La relation de récurrence est :
$$
DP[s][c][S] = max\{ DP [p-1][c'][S'] + w[p] s[i] \}
$$
avec 

* $p$ : nombre d'éléments
* $c=(c[1], c[2], ..., c[G])$ : vecteur des compteurs par groupe
* $S$ : ensemble des éléments déjà utilisés
* $DP[s][c][S]$ : meilleur score pour avoir sélectionné p éléments avec configuration $c$ et ensemble $S$.

## Exemple concret

On applique l'algorithme une nouvelle fois sur le jeu de données décrit en introduction :


```{r, echo=FALSE, message=FALSE}
# Résolution
result <- ranking_max(data_mat, k, max_par_groupe, poids_positions = poids_positions)

result$selected_items %>%
  select(position, id, score, group_list, poids_position, score_pondere) %>%
  kable(
    format = "latex",              
    booktabs = TRUE,               
    align = "c",
    col.names = c("Position", "ID", "Score", "Groupe", "Poids position", "Score pondéré"),
    caption = "Tableau des éléments sélectionnés par l'algorithme ranking max",
    escape = TRUE                 
  ) %>%
  kable_styling(
    latex_options = c("striped", "hold_position"),  
    full_width = FALSE
  ) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(6, bold = TRUE)

```


Visualisation : contribution par position
```{r, out.width='80%', echo=FALSE, message=FALSE}
result$score_pondere <- result$score * result$poids

df <- result$selected_items

ggplot(df, aes(x = factor(position), y = score_pondere)) +
  geom_col(fill="steelblue") +
  labs(title="Contribution pondérée par position",
       x="Position", y="Score pondéré") +
  theme_minimal()
```

Le graphique montre que les positions les mieux pondérées (1 et 2) contribuent le plus au score total. Il permet de visualiser l'impact de chaque choix sur le score global.


# 4. Solution 2 : programmation dynamique et tas 

Pour des ensembles de données plus volumineux, la programmation dynamique  peut devenir très coûteuse en temps et en mémoire, car le nombre d'états possibles croît de manière exponentielle avec le nombre de positions (k) et le nombre de groupes (G).

Pour améliorer l'algorithme, nous utilisons une approche approximative avec Beam Search, elle conserve uniquement beam_size meilleurs états à chaque niveau, on a alors une approximation proche de l'optimum.

### Principe algorithmique

1. Représentation des états, chaque état est défini par :

   * le score cumulé des éléments sélectionnés,
   * le compteur d'éléments choisis par groupe,
   * les Id des éléments sélectionnés précédemment.

2. Pour chaque position :

   * Pour chaque état conservé, on génère de nouveaux états en ajoutant chaque élément disponible respectant les contraintes.
   * On ajoute ces états dans un tas et ne garde que "beam_size" meilleurs états (pruning).

3. À la fin, on reconstruit la sélection à partir du meilleur état final.


### Un exemple

On reprend l'exemple précédent avec un **beam de taille 100** :

```{r, warning=FALSE, echo=FALSE, message=FALSE}
library(Rcpp)

res <- ranking_max_dp_heap_cpp(data_mat, k, max_par_groupe, poids_positions, beam_size = 100)
print(res)
```

On reprend l'exemple précédent, avec un **beam de taille différente égale à 5000** :

```{r, warning=FALSE, echo=FALSE, message=FALSE}
library(Rcpp)

res <- ranking_max_dp_heap_cpp(data_mat, k, max_par_groupe, poids_positions, beam_size = 5000)
print(res)
```

* Le champ `approximation` indique si la solution a été tronquée par le beam.

* Même avec un beam très limité, l'algorithme tend à sélectionner les éléments avec les meilleurs scores** tout en respectant les contraintes de groupe. Augmenter la taille du beam ne fait qu'augmenter légèrement la fonction objective. 

* La programmation dynamique combinée à un heap permet de garder les meilleures solutions intermédiaires sans générer tous les états possibles, ce qui est crucial pour de grands ensembles de données.

 
# 5. Comparaison de la performance

```{r}

set.seed(13)

num_instances <- 50   # nombre d'instances
n_items <- 10         # items par instance
k <- 5                # positions
ratios1 <- numeric(num_instances)
ratios2 <- numeric(num_instances)


df <- read.csv("amazon_products_250.csv", stringsAsFactors = FALSE)
df$sponsored <- ifelse(df$sponsored == "True", "Sponsored", "Not_sponsored")

# Poids de position 
poids_positions <- seq(k, 1, by = -1) 

# Création des listes de contraintes
liste_cat <- setNames(as.list(rep(2, length(unique(df$category)))),
                      unique(df$category))
max_par_groupe <- c(liste_cat, list(Not_sponsored = 9))

for (i in 1:num_instances)
{
  echantillon <- df[sample(nrow(df), min(n_items, nrow(df))), ]
  data_mat <- data.frame(
    id = 1:nrow(echantillon),
    score = echantillon$score,
    groupes = paste(echantillon$category, 
                    echantillon$sponsored, sep = ",")
  )
  V_g <- ranking_naif_max(data_mat,k,max_par_groupe,poids_positions)$best_score
  V_opt <- ranking_max_cpp(data_mat,k,max_par_groupe,poids_positions)$best_score
  V_dp_heap <- ranking_max_dp_heap_cpp(data_mat,k,max_par_groupe,poids_positions)$best_score
  
  ratios1[i] <- V_g / V_opt
  ratios2[i] <- V_dp_heap / V_opt
  
}

boxplot(ratios1, ratios2, names=c("Naif", "DP Heap"),
        main="Comparaison des ratios valeur trouvée / optimum n=10",
        ylab="Ratio / Optimum", col=c("red","blue"))
```

```{r}
set.seed(13)

num_instances <- 50   # nombre d'instances
n_items <- 200         # items par instance
k <- 5                # positions
ratios1 <- numeric(num_instances)
ratios2 <- numeric(num_instances)


df <- read.csv("amazon_products_250.csv", stringsAsFactors = FALSE)
df$sponsored <- ifelse(df$sponsored == "True", "Sponsored", "Not_sponsored")

# Poids de position 
poids_positions <- seq(k, 1, by = -1) 

# Création des listes de contraintes
liste_cat <- setNames(as.list(rep(2, length(unique(df$category)))),
                      unique(df$category))
max_par_groupe <- c(liste_cat, list(Not_sponsored = 9))

for (i in 1:num_instances)
{
  echantillon <- df[sample(nrow(df), min(n_items, nrow(df))), ]
  data_mat <- data.frame(
    id = 1:nrow(echantillon),
    score = echantillon$score,
    groupes = paste(echantillon$category, 
                    echantillon$sponsored, sep = ",")
  )
  V_g <- ranking_naif_max(data_mat,k,max_par_groupe,poids_positions)$best_score
  V_opt <- ranking_max_cpp(data_mat,k,max_par_groupe,poids_positions)$best_score
  V_dp_heap <- ranking_max_dp_heap_cpp(data_mat,k,max_par_groupe,poids_positions)$best_score
  
  ratios1[i] <- V_g / V_opt
  ratios2[i] <- V_dp_heap / V_opt
  
}

boxplot(ratios1, ratios2, names=c("Naif", "DP Heap"),
        main="Comparaison des ratios valeur trouvée / optimum n=200",
        ylab="Ratio / Optimum", col=c("red","blue"))
```

On constate que l'approche heuristique fonctionne très bien alors que la programmation dynamique avec tas ne trouve pas toujours la solution optimale. 

Si l'algorithme naif trouve presque toujours la solution optimale, voici un exemple où ce n'est pas le cas :

```{r}
data <- data.frame(
  id = 1:6,
  score = c(5, 4.8, 4.7, 4.6, 4, 3),
  groupes = c("A,S", "A,S", "A", "B,S", "C,S", "C,S")
)
max_par_groupe <- list(A = 2, B = 2, C = 2, S = 4)
poids_positions <- seq(k, 1, by = -1) 

cat("Resultat naif\n")
resultat_naif <- ranking_naif_max(data, 5, max_par_groupe, poids_positions)
print(resultat_naif)

cat("Resultat programmation dynamique\n")
resultat_dp <- ranking_max_cpp(data, 5, max_par_groupe, poids_positions)
print(resultat_dp)
```



# 6. Complexité des algorithmes (par le calcul)

Voici nos 4 algorithmes :

1. **Algorithme naïf R**
2. **Algorithme dynamique R**
3. **Algorithme dynamique C++ **
4. **Algorithme dynamique C++ amélioré (beam search)**

Pour chacun, nous analysons la complexité temps (meilleur, pire, moyenne)
Les paramètres en jeu sont :  

* **n** : nombre d'items (taille de l'entrée)

* **G** : nombre de groupes

* **k** : nombre de positions à remplir

* **M** : nombre théorique maximal d'états = $\prod_{g=1}^G (\text{max\_cap}_g + 1)$

* **$\bar{g}$** : nombre moyen de groupes par item


## 1. Algorithme Naïf Glouton (R)

Sélection gloutonne : pour chaque position p, parcourir tous les candidats restants et choisir celui au meilleur gain immédiat $w_p \times \text{score}_i$.

### Analyse détaillée

**Étape 1 - Initialisation** : $O(G)$

* Création des structures de données
* Négligeable devant la boucle principale

**Étape 2 - Boucle principale**

Pour chaque position $p = 1, \ldots, k$ :

- Nombre d'items restants à examiner : $n - (p-1)$

- Pour chaque item candidat :
  * Parser les groupes : $O(G)$ 
  * Vérifier les contraintes : $O(G)$ comparaisons
  * Calculer le gain : $O(1)$
  
- Mise à jour des compteurs : $O(G)$

Coût pour la position $p$ :
$$T_p = O((n - p + 1) \times G)$$

Coût total de la boucle :
$$T_{\text{boucle}} = \sum_{p=1}^{k} O((n - p + 1) \times G) = O\left(G \times \left(kn - \frac{k(k-1)}{2}\right)\right) \approx O(k n G)$$

### Complexité temporelle

$$\boxed{T_{\text{naïf}}(n) = O(k n G)}$$

**Meilleur cas** : $\boxed{T(n) = O(kn)}$ si $G = O(1)$

**Cas moyen** : $\boxed{T(n) = O(k n \bar{g})}$

**Pire cas** : $\boxed{T(n) = O(k n G)}$



## 2. Algorithme DP (R)

Programmation dynamique avec états définis par $(p, c_1, \ldots, c_G)$ où $c_g$ = nombre d'items du groupe $g$ déjà utilisés.

### Analyse détaillée

**Étape 1 - Prétraitement** : $O(nG)$

- Parser les groupes de chaque item : $O(n G)$
- Créer la matrice binaire `item_groups` : $O(nG^2)$

**Étape 2 - Programmation dynamique**

Structure : `DP[[p+1]][[key]]` avec `key = "c1,c2,...,cG"`

Nous obtenu ce calcul : $O(k) + O(k) + O(k)(O(G) + O(n)( O(k) + O(G) + O(G))$


**Étape 3 - Recherche du meilleur** : $O(G)$

### Complexité temporelle

$$\boxed{T_{\text{DP-R}}(n) = O(n k^2 G^2)}$$

**Meilleur cas** : $\boxed{T(n) = O(nk^2)}$

**Cas moyen** : $\boxed{T(n) = O(nk^2\bar g^2)}$ 

**Pire cas** : $\boxed{T(n) = O(nk^2G^2)}$


## 3. Algorithme DP (C++)

Même logique que DP R, voici la complexité.

### Complexité temporelle

$$\boxed{T_{\text{DP-R}}(n) = O(n k^2 G^2)}$$

**Meilleur cas** : $\boxed{T(n) = O(nk^2)}$

**Cas moyen** : $\boxed{T(n) = O(nk^2\bar g^2)}$ 

**Pire cas** : $\boxed{T(n) = O(nk^2G^2)}$


## 4. Algorithme dynamique amélioré (C++)

DP avec pruning : conserve uniquement les `beam_size` meilleurs états à chaque niveau.

### Analyse détaillée

Soit $B = \min(\text{beam\_size}, M)$ le nombre effectif d'états conservés.

**Étape 1 - Tri initial** : $O(n \log n)$

Items triés par score décroissant pour améliorer la qualité des états gardés.

**Étape 2 - DP avec tas (priority_queue)**

Pour chaque position $p$, chaque état (max $B$), chaque item $n$ :

- Extraction des états du tas : $O(B \log B)$ (une fois par niveau)

- Pour chaque état × item :
  * Calcul compteurs : $O(G)$
  * Make key : $O(G)$
  * Push dans tas : $O(\log B)$
  * Pruning si nécessaire : $O(\log B)$

Coût par niveau : $T_p = O(B \log B) + O(nB(G + \log B))$

Si $G \geq \log B$ (généralement vrai) :

$$T_p = O(nBG)$$

Sur $k$ niveaux :

$$T_{\text{DP}} = O(nkBG)$$

**Étape 3 - Recherche meilleur** : $O(kB)$

**Étape 4 - Reconstruction** : $O(n)$

### Complexité temporelle

$$\boxed{T_{\text{Beam}}(n) = O(n \log n + nkBG)}$$

Si $nkBG \gg n \log n$ : $\boxed{T_{\text{Beam}}(n) = O(nkBG)}$

**Meilleur cas** : $\boxed{T(n) = O(n \log n + nkG)}$ si $B = 1$

**Cas moyen** : $\boxed{T(n) = O(n \log n + nkBG)}$ avec $B$ modéré (100-10000)

**Pire cas** : $\boxed{T(n) = O(n \log n + nkBG)}$ (même formule, $B$ peut être grand)


**Avantage majeur** : Complexité **contrôlable** via `beam_size`, contrairement aux versions exactes.



## Tableau récapitulatif

| Algorithme           | Meilleur cas            | Cas moyen              | Pire cas                    |
|----------------------|-------------------------|------------------------|-----------------------------|
| **Naïf R**           | $O(kn)$                 | $O(kn\bar{g})$         | $O(knG)$                    |
| **DP R**             | $O(nk^2)$               | $O(nk^2\bar{g^2})$     | $O(nk^2G^2)$                |
| **DP C++**           | $O(nk^2)$               | $O(nk^2\bar{g^2})$     | $O(nk^2G^2)$                |
| **Beam C++**         | $O(n \log n + nkG)$     | $O(n \log n + nkBG)$   | $O(n \log n + nkBG)$        |


## Comparaison graphique

```{r complexity-comparison, echo=FALSE, message=FALSE, warning=FALSE, fig.width=12, fig.height=6}
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)

# Paramètres de simulation
n_values <- seq(100, 2000, length.out = 200)
G <- 5
k <- 20
g_bar <- 2  # nombre moyen de groupes par item
B <- 1000   # Beam size
M <- (3+1)^G  # Pire cas avec cap_g = 3 pour chaque groupe

# === CAS MOYEN ===
df_moyen <- data.frame(
  n = n_values,
  Naive = k * n_values * g_bar,
  DP_R = n_values * k^2 * g_bar * g_bar,
  DP_Cpp = n_values * k^2 * g_bar * g_bar / 10,  # Facteur constant 10x plus petit
  Beam = n_values * log(n_values) + B * n_values * k * G
)

df_moyen_long <- df_moyen %>%
  pivot_longer(-n, names_to = "algo", values_to = "operations") %>%
  mutate(algo = factor(algo, levels = c("Naive", "DP_R", "DP_Cpp", "Beam")))

p1 <- ggplot(df_moyen_long, aes(x = n, y = operations, color = algo)) +
  geom_line(size = 1.2) +
  scale_y_log10(
    labels = comma,
    breaks = 10^(3:10)
  ) +
  scale_color_manual(
    values = c(
      "Naive" = "#E74C3C",
      "DP_R" = "#3498DB",
      "DP_Cpp" = "#2ECC71",
      "Beam" = "#9B59B6"
    ),
    labels = c(
      "Naive" = "Naïf R",
      "DP_R" = "DP R",
      "DP_Cpp" = "DP C++",
      "Beam" = "Beam C++"
    )
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = sprintf("Cas moyen (G=%d, k=%d, S=%d, B=%d)", G, k, S, B),
    x = "Nombre d'items (n)",
    y = "Nombre d'opérations (échelle log)",
    color = "Algorithme"
  )

# === PIRE CAS ===
df_pire <- data.frame(
  n = n_values,
  Naive = k * n_values * G,
  DP_R = pmin(M * n_values * k * G, 1e12),  # Limité pour visibilité
  DP_Cpp = pmin(M * n_values * k * G / 10, 1e12),
  Beam = n_values * log(n_values) + B * n_values * k * G
)

df_pire_long <- df_pire %>%
  pivot_longer(-n, names_to = "algo", values_to = "operations") %>%
  mutate(algo = factor(algo, levels = c("Naive", "DP_R", "DP_Cpp", "Beam")))

p2 <- ggplot(df_pire_long, aes(x = n, y = operations, color = algo)) +
  geom_line(size = 1.2) +
  scale_y_log10(
    labels = comma,
    breaks = 10^(3:12)
  ) +
  scale_color_manual(
    values = c(
      "Naive" = "#E74C3C",
      "DP_R" = "#3498DB",
      "DP_Cpp" = "#2ECC71",
      "Beam" = "#9B59B6"
    ),
    labels = c(
      "Naive" = "Naïf R",
      "DP_R" = "DP R (plafonné)",
      "DP_Cpp" = "DP C++ (plafonné)",
      "Beam" = "Beam C++"
    )
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = sprintf("Pire cas (G=%d, k=%d, M=%s, B=%d)", G, k, comma(M), B),
    x = "Nombre d'items (n)",
    y = "Nombre d'opérations (échelle log)",
    color = "Algorithme",
    caption = "Note: DP R et DP C++ plafonnés à 10^12 pour la lisibilité"
  )

# Afficher les graphiques
print(p1)
print(p2)
```

### Observations

**Cas moyen** :

* Beam Search et DP C++ sont très compétitifs
* DP R significativement plus lent (facteur 10)
* Naïf acceptable pour petites instances

**Pire cas** :

* Explosion exponentielle des DP exact (R et C++)
* Beam Search reste linéaire et prévisible
* Seul algorithme viable pour grands problèmes avec $G \geq 6$


## Impact du nombre de groupes G

```{r impact-groups, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=6}
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)

# Paramètres fixes
n <- 1000
k <- 20
S <- 200
B <- 1000
cap <- 3  # capacité moyenne par groupe

# Variation de G
G_values <- 2:10

# Calcul de M pour chaque G
M_values <- (cap + 1)^G_values

df_impact <- data.frame(
  G = G_values,
  M = M_values,
  Naive = k * n * G_values,
  DP_moyen = S * n * k * G_values,
  DP_pire = M_values * n * k * G_values,
  Beam = B * n * k * G_values
)

# On limite DP_pire pour la visualisation
df_impact$DP_pire_display <- pmin(df_impact$DP_pire, 1e15)

df_impact_long <- df_impact %>%
  select(G, Naive, DP_moyen, DP_pire_display, Beam) %>%
  pivot_longer(-G, names_to = "algo", values_to = "operations") %>%
  mutate(
    algo = factor(
      algo,
      levels = c("Naive", "DP_moyen", "DP_pire_display", "Beam"),
      labels = c("Naïf", "DP cas moyen", "DP pire cas", "Beam")
    )
  )

ggplot(df_impact_long, aes(x = G, y = operations, color = algo)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  scale_y_log10(
    labels = comma,
    breaks = 10^seq(4, 16, by = 2)
  ) +
  scale_x_continuous(breaks = G_values) +
  scale_color_manual(
    values = c(
      "Naïf" = "#E74C3C",
      "DP cas moyen" = "#2ECC71",
      "DP pire cas" = "#3498DB",
      "Beam" = "#9B59B6"
    )
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold", size = 16),
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = sprintf("Impact du nombre de groupes G (n=%d, k=%d)", n, k),
    x = "Nombre de groupes (G)",
    y = "Nombre d'opérations (échelle log)",
    color = "Algorithme",
    caption = sprintf("Capacité moyenne par groupe = %d | DP pire cas plafonné à 10^15", cap)
  )
```

### Analyse

- **G $\le$ 4** : Tous les algorithmes sont viables
- **G = 5-6** : DP commence à être problématique en pire cas
- **G >= 7** : Seul Beam Search reste praticable
- L'explosion de M = (cap+1)^G rend DP exact inutilisable pour grand G


# 7. Temps de calcul 

```{r}
set.seed(123)

n <- c(20,22,25,32,42,55,70,90,125,160,200,250)
temps_moyens1 <- numeric(length(n))
temps_moyens2 <- numeric(length(n))
temps_moyens3 <- numeric(length(n))
temps_moyens4 <- numeric(length(n))
k <- 5

df <- read.csv("amazon_products_250.csv", stringsAsFactors = FALSE)
df$sponsored <- ifelse(df$sponsored == "True", "Sponsored", "Not_sponsored")

# Poids de position 
poids_positions <- seq(k, 1, by = -1) 

# Création des listes de contraintes
liste_cat <- setNames(as.list(rep(2, length(unique(df$category)))),
                      unique(df$category))
max_par_groupe <- c(liste_cat, list(Not_sponsored = 4))

for (i in 1:length(n))
{
  echantillon <- df[sample(nrow(df), min(n[i], nrow(df))), ]
  data_mat <- data.frame(
    id = 1:nrow(echantillon),
    score = echantillon$score,
    groupes = paste(echantillon$category, 
                    echantillon$sponsored, sep = ",")
  )
  
  start_time1 <- Sys.time()
  res1 <- ranking_naif_max(data_mat, k = k, max_par_groupe, poids_positions = poids_positions)
  end_time1 <- Sys.time()
  elapsed_time1 <- as.numeric(difftime(end_time1, start_time1, units = "secs"))
  temps_moyens1[i] <- elapsed_time1
  
  start_time2 <- Sys.time()
  res2 <- ranking_max(data_mat, k = k, max_par_groupe, poids_positions = poids_positions)
  end_time2 <- Sys.time()
  elapsed_time2 <- as.numeric(difftime(end_time2, start_time2, units = "secs"))
  temps_moyens2[i] <- elapsed_time2
  
  start_time3 <- Sys.time()
  res3 <- ranking_max_cpp(data_mat, k = k, max_par_groupe, poids_positions = poids_positions)
  end_time3 <- Sys.time()
  elapsed_time3 <- as.numeric(difftime(end_time3, start_time3, units = "secs"))
  temps_moyens3[i] <- elapsed_time3
  
  start_time4 <- Sys.time()
  res4 <- ranking_max_dp_heap_cpp(data_mat, k = k, max_par_groupe, poids_positions = poids_positions)
  end_time4 <- Sys.time()
  elapsed_time4 <- as.numeric(difftime(end_time4, start_time4, units = "secs"))
  temps_moyens4[i] <- elapsed_time4
}

cat("Temps pour l'algorithme naif\n")
temps_moyens1
cat("Temps pour l'algorithme de programmation dynamique\n")
temps_moyens2
cat("Temps pour l'algorithme de programmation dynamique (en C++)\n")
temps_moyens3
cat("Temps pour l'algorithme de programmation dynamique avec tas (en C++)\n")
temps_moyens4

```



```{r}
par(mfrow=c(2,2))

# Graphique 1
res1 <- data.frame(
  n = n,
  time = temps_moyens1
)
plot(log(res1$n), log(res1$time), pch=16,
     xlab="Taille des séquences : n (log)",
     ylab="Temps (s, log)",
     main="Algo naif (log-log)")
abline(lm(log(time) ~ log(n), data=res1), col="red")

# Graphique 2
res2 <- data.frame(
  n = n,
  time = temps_moyens2
)
plot(log(res2$n), log(res2$time), pch=16,
     xlab="Taille des séquences : n (log)",
     ylab="Temps (s, log)",
     main="Algo dp (R) (log-log)")
abline(lm(log(time) ~ log(n), data=res2), col="red")

# Graphique 3
res3 <- data.frame(
  n = n,
  time = temps_moyens3
)
plot(log(res3$n), log(res3$time), pch=16,
     xlab="Taille des séquences : n (log)",
     ylab="Temps (s, log)",
     main="Algo dp (C++) (log-log)")
abline(lm(log(time) ~ log(n), data=res3), col="red")

# Graphique 4
res4 <- data.frame(
  n = n,
  time = temps_moyens4
)
plot(log(res4$n), log(res4$time), pch=16,
     xlab="Taille des séquences : n (log)",
     ylab="Temps (s, log)",
     main="Algo dp avec tas (C++) (log-log)")
abline(lm(log(time) ~ log(n), data=res4), col="red")

par(mfrow=c(1,1))
```

```{r}

modele1 <- lm(log(time) ~ log(n), data = res1)
summary(modele1)

modele2 <- lm(log(time) ~ log(n), data = res2)
summary(modele2)

modele3 <- lm(log(time) ~ log(n), data = res3)
summary(modele3)

modele4 <- lm(log(time) ~ log(n), data = res4)
summary(modele4)
```


```{r}
# Couleurs pour chaque algorithme
cols <- c("blue", "red", "green", "purple")

# Déterminer les limites de l'axe x et y pour inclure toutes les données
xlim <- range(log(res1$n), log(res2$n), log(res3$n), log(res4$n))
ylim <- range(log(res1$time), log(res2$time), log(res3$time), log(res4$time))

# Graphique vide pour préparer l'affichage
plot(NA, NA, xlim=xlim, ylim=ylim,
     xlab="Taille des séquences : n (log)",
     ylab="Temps (s, log)",
     main="Comparaison des algorithmes (log-log)")

# Ajouter les 4 séries de points
points(log(res1$n), log(res1$time), pch=16, col=cols[1])
points(log(res2$n), log(res2$time), pch=16, col=cols[2])
points(log(res3$n), log(res3$time), pch=16, col=cols[3])
points(log(res4$n), log(res4$time), pch=16, col=cols[4])

# Ajouter les droites de régression
abline(lm(log(time) ~ log(n), data=res1), col=cols[1], lwd=2)
abline(lm(log(time) ~ log(n), data=res2), col=cols[2], lwd=2)
abline(lm(log(time) ~ log(n), data=res3), col=cols[3], lwd=2)
abline(lm(log(time) ~ log(n), data=res4), col=cols[4], lwd=2)

# Ajouter la légende
legend("topleft",
       legend=c("Algo naif", "DP (R)", "DP (C++)", "DP + tas (C++)"),
       col=cols, pch=16, lwd=2,
       cex=0.6)

```


Les graphiques en échelle *log-log* montrent que chaque algorithme suit une relation de type  
\( T(n) \propto n^{\alpha} \), ce que confirment les régressions linéaires dont les coefficients de détermination sont très élevés (R² > 0.96).  
Les pentes estimées permettent de comparer directement la croissance du temps de calcul entre algorithmes.

- **Algorithme naïf (R)** : la pente (~0.93) indique une croissance presque linéaire. L’algorithme est très rapide mais ne garantit pas l’optimalité.

- **Programmation dynamique (R)** : la pente élevée (~1.96) montre une forte augmentation du temps de calcul. L’algorithme devient difficilement utilisable lorsque \( n > 100 \).

- **Programmation dynamique (C++)** : la pente plus faible (~1.7) reflète une complexité mieux contrôlée. L’implémentation est environ 100× plus rapide que celle en R.

- **Programmation dynamique avec tas (C++)** : la croissance du temps reste modérée avec une pente d'environ 1.27, même pour de grandes valeurs de \( n \). Si on utiliserait des valeurs plus grandes que celle testées, le temps de cet algorithme serait moins important que celui d'une programmation dynamique standard. 


# Conclusion

**Choix de l'algorithme selon le contexte**

| Contexte | Algorithme recommandé | Justification |
|----------|----------------------|---------------|
| Petits problèmes (n<100, G<3, k<10) | **DP C++** | Simple, rapide, optimal |
| Moyens problèmes (n<1000, G<5, k<20) | **Naïf R** ou **DP C++** | Optimal (garanti pour DP C++), performance acceptable |
| Grands problèmes (n>1000 ou G>5) | **Naïf R** | Seul viable, quasi-optimal |
| Recherche d'optimum prouvé | **DP C++** si faisable | Exact mais peut échouer |


